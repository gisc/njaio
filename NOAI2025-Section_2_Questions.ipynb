{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d993e321-9a95-4ba5-92a6-6bfd33ffe0e3",
   "metadata": {},
   "source": [
    "# Section 2: Programming Questions (Total 80 marks)\n",
    "- This section contains 3 questions.\n",
    "- You are provided with Python 3.9 Standard Library and NumPy Library.\n",
    "- Python 3.9 Documentation: https://docs.python.org/3.9/\n",
    "- NumPy Documentation: https://numpy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad75ad-048c-45f0-9032-e6f893a6aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589b9dd-31e2-4b91-980d-cb4edaee9799",
   "metadata": {},
   "source": [
    "***\n",
    "## Question 1: Linear Regression Using Gradient Descent (15 marks)\n",
    "***\n",
    "Linear Regression can also be performed using a technique called gradient descent, where the coefficients (or weights) of the model are iteratively adjusted to minimise a cost function (usually mean squared error). This method is particularly useful when the numbers of features is too large for analytical solutions like the normal equation or when the feature matrix is not invertible. <br><br>\n",
    "\n",
    "The gradient descent algorithm updates the weights by moving in the direction of the negative gradient of the cost function with respect to the weights. The updates occur iteratively until the algorithm converges to a minimum of the cost function. <br><br>\n",
    "\n",
    "The update rule for each weight is given by: <br>\n",
    "\n",
    "$$θ_j := θ_j - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(h_θ(x^i)-y^i)x_j^i$$\n",
    "\n",
    "**Explanation of Terms**\n",
    "1. $α$ is the learning rate.\n",
    "2. $m$ is the number of training examples.\n",
    "3. $h_θ(x^i)$ is the hypothesis function at iteration $i$.\n",
    "4. $x^i$ is the feature vector of $i_{th}$ training example.\n",
    "5. $y^i$ is the actual target value for the $i_{th}$ training example.\n",
    "6. $x_j^i$ is the value of feature $j$ for the $i_{th}$ training example.<br><br>\n",
    "\n",
    "**Key Points**\n",
    "- **Learning Rate**: The choice of learning rate is crucial for the convergence and performance of gradient descent.\n",
    "  - A small learning rate may lead to slow convergence.\n",
    "  - A large learning rate may cause overshooting and divergence.\n",
    "- **Number of Iterations**: The number of iterations determines how long the algorithm runs before it converges or stops.<br><br>\n",
    "\n",
    "**Practical Implementation**<br>\n",
    "Implementing gradient descent involves initialising the weights, computing the gradient of the cost function, and iteratively updating the weights according to the update rule.\n",
    "\n",
    "## Task #1\n",
    "- The function should take\n",
    "  - NumPy arrays X (features with a column of values for the intercept);\n",
    "  - y (target) as input;\n",
    "  - learning rate alpha;\n",
    "  - the number of iterations;\n",
    "  - return the coefficients of the linear regression model as a NumPy array.\n",
    "- Round your answer to four decimal places. -0.0 is a valid result for rounding a very small number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcc00b-7aee-46bf-88a0-a8dbfdbc0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MAKE CHANGES TO THIS CELL\n",
    "\n",
    "X = np.array([[2, 2], [2, 4], [2, 6]])\n",
    "y = np.array([2, 4, 6])\n",
    "alpha = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280aedd8-424d-452f-b102-45434de1706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> np.ndarray:\n",
    "    # your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185069c1-a46c-458d-911a-e224249c81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MAKE CHANGES TO THIS CELL\n",
    "\n",
    "linear_regression_gradient_descent(X=X, y=y, alpha=alpha, iterations=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa58e3-05d0-401b-8561-b953abefa3d5",
   "metadata": {},
   "source": [
    "***\n",
    "## Question 2: K-Means Clustering (25 marks)\n",
    "***\n",
    "1. **Initialisation**<br>\n",
    "  Use the provided `initial_centroids` as your starting point.<br>\n",
    "\n",
    "2. **Assignment Step**<br>\n",
    "  For each point in your dataset:\n",
    "    - Calculate its distance to each centroid.\n",
    "    - Assign the point to the cluster of the nearest centroid.<br>\n",
    "      *Hint: Consider creating a helper function to calculate the Euclidean distance between two points.*\n",
    "\n",
    "3. **Update Step**<br>\n",
    "  For each cluster:\n",
    "    - Calculate the mean of all points assigned to the cluster.\n",
    "    - Update the centroid to this new mean position.<br>\n",
    "      *Hint: Be careful with potential empty clusters. Decide how you will handle them (eg. keep the previous centroid).*\n",
    "\n",
    "4. **Iteration**<br>\n",
    "  Repeat Step 2 and 3 until either:\n",
    "    - The centroids no longer change significantly, OR\n",
    "    - `max_iterations` reached.<br>\n",
    "      *Hint: You might want to keep track of the previous centroids to check for significant changes.*\n",
    "\n",
    "5. **Result**<br>\n",
    "  Return the list of final centroids, ensuring each coordinate is rounded to the nearest fourth decimal.\n",
    "\n",
    "## Task #2\n",
    "- Write a Python function that implements the K-Means clustering algorithm.\n",
    "  - This function should take specific inputs and produce a list of final centroids.\n",
    "  - K-Means clustering is a method used to partition *n* points into *k* clusters.\n",
    "  - The goal is to group similar points together and represent each group by its centroid.\n",
    "\n",
    "- Function Inputs:\n",
    "  - points: list of points, where each point is a tuple of coordinates (e.g., (x, y) for 2D points)\n",
    "  - *k*: an integer representing the number of clusters to form\n",
    "  - `initial_centroids`: list of initial centroid points, each a tuple of coordinates\n",
    "  - `max_iterations`: an integer representing the maximum number of iterations to perform\n",
    "\n",
    "- Function Output:\n",
    "  - A list of the final centroids of the clusters, where each centroid is rounded to the nearest fourth decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ace16-d8b0-46e1-8d7f-11b1da66da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MAKE CHANGES TO THIS CELL\n",
    "\n",
    "points = [(2, 4), (2, 8), (2, 10), (10, 2), (10, 4), (10, 0)]\n",
    "k = 2\n",
    "initial_centroids = [(2, 2), (10, 1)]\n",
    "max_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efa2b0-b2a9-4d20-ba16-9a68eb002334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    # your code here\n",
    "    return\n",
    "\n",
    "def k_means_clustering(points, k, initial_centroids, max_iterations):\n",
    "    # your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c4048-725c-4980-8e54-17d2d1882c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MAKE CHANGES TO THIS CELL\n",
    "\n",
    "k_means_clustering(points=points, k=k, initial_centroids=initial_centroids, max_iterations=max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190795a-4ac3-4610-b3e8-b84b6a5e7b91",
   "metadata": {},
   "source": [
    "***\n",
    "## Question 3: Retrieval Augmented Generation (40 marks)\n",
    "***\n",
    "### Background\n",
    "\n",
    "In a classroom filled with curious students, Ms. Sally stood at the front with a confident smile.\n",
    "\n",
    "She had promised her class an engaging lesson on a cutting-edge technology: Artificial Intelligence.\n",
    "\n",
    "\"Alright, class,\" she began, holding a few printed notes in her hand. \"Let's build a smart assistant that can answer your questions using only a set of documents. \n",
    "\n",
    "Let’s say the question is: ‘How does machine learning work?’\n",
    "\n",
    "The smart assistant is to extract the content from the given set of documents and answer the question.\n",
    "\n",
    "This is done with a 2-step process: \"Retrieve and Generate\"\n",
    "\n",
    "The set of documents can be found below:\n",
    "\n",
    "1. Artificial intelligence is transforming industries.\n",
    "2. Machine learning is a subset of artificial intelligence.\n",
    "3. Deep learning allows machines to solve complex problems.\n",
    "4. Data science involves statistics and machine learning.\n",
    "5. Neural networks are inspired by the human brain.\n",
    "\n",
    "\"Which one of these do you think would help answer the question?\" she asked. \n",
    "\n",
    "A few hands shot up and answered it.\n",
    "\n",
    "\"That’s right! The second and fourth ones mentioned machine learning directly,\" she confirmed.\n",
    "\n",
    "\"Now the smart assistant has to take what it found and turn it into a formulated response: ‘Machine learning is a subset of artificial intelligence that enables systems to learn from data. It involves techniques like statistics and algorithms often used in data science.’ \n",
    "\n",
    "See how it combines ideas from the documents to explain the concept?\"\n",
    "\n",
    "## Task #3\n",
    "\n",
    "The goal is to retrieve the most relevant information from these documents and generate an accurate, concise, and meaningful response to the query.<br>\n",
    "\n",
    "The solution will be a simple Retrieval Augumented Generation solution that includes but not limited to the following:<br>\n",
    "i. Feature Extraction such as vectorisation technique to represent the documents as numerical vectors that capture their semantic meaning and relevance to the question.<br>\n",
    "  - A common approach is **TF-IDF** (Term Frequency-Inverse Document Frequency):<br>\n",
    "    - **Term Frequency (TF)**: How often a word appears in a document\n",
    "    - **Inverse Document Frequency (IDF)**: How rare or common a word is across all documents\n",
    "\n",
    "ii. Once you have numerical vectors for the documents and query, you can measure how similar they are using similarity scoring such as cosine similarity.<br>\n",
    "  - Cosine similarity measures the angle between two vectors\n",
    "  - Values range from 0 (completely different) to 1 (exactly the same)\n",
    "  - The higher the score, the more relevant a document is to the query\n",
    "\n",
    "### Expected output\n",
    "\n",
    "Query: How does machine learning work?\n",
    "\n",
    "Generated Response:\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn from data. It involves techniques like statistics and algorithms, often used in data science.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b81d61-5e7f-4e5c-b5ab-97156ce6d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MAKE CHANGES TO THIS CELL\n",
    "\n",
    "# Set of documents\n",
    "documents = [\n",
    "    \"Artificial intelligence is transforming industries.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning allows machines to solve complex problems.\",\n",
    "    \"Data science involves statistics and machine learning.\",\n",
    "    \"Neural networks are inspired by the human brain.\"\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"How does machine learning work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf338c-9ae6-4f92-b0f5-ea0e6dc43176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c215d06-6a9e-4ee5-8ad2-84b9af2d8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MAKE CHANGES TO THIS CELL\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nRetrieved Documents:\")\n",
    "for doc in top_documents:\n",
    "    print(\"-\", doc)\n",
    "\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecd524-5874-4d8d-a14d-d1ba201acc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share your thought process on how you derive at your solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

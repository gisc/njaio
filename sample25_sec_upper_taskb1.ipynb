{
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":["# Task B1 — Supervised Learning (NumPy)\n","Upper Secondary / Section B — Structured Tasks\n\n","Constraints: Use Python 3 and NumPy only (no external libraries).\n\n","This task has three parts:\n","- Structured Theory Questions\n","- Design Challenge\n","- Practical Programming (gradient descent for 1D linear regression)"]},
  {"cell_type":"markdown","metadata":{},"source":["## Structured Theory Questions\n","1. What is supervised learning? Provide a concise definition.\n","2. What does Mean Squared Error (MSE) measure?\n","3. How can the choice of learning rate affect convergence?"]},
  {"cell_type":"markdown","metadata":{},"source":["## Design Challenge\n","You are given a tiny dataset of study hours vs scores.\n","- Propose a learning-rate schedule (constant vs simple decay) and justify your choice.\n","- State a stopping criterion (fixed iterations or When |update| < epsilon). Explain briefly."]},
  {"cell_type":"code","metadata":{},"execution_count":null,"source":["import numpy as np"]},
  {"cell_type":"markdown","metadata":{},"source":["## Provided Data\n","The relationship is approximately `score ≈ 2 * hours`. We use small integer values to keep the task simple."]},
  {"cell_type":"code","metadata":{},"execution_count":null,"source":["# DO NOT MODIFY\n","X = np.array([[1.0], [2.0], [3.0], [4.0]])  # shape (m, 1)\n","y = np.array([2.0, 4.0, 6.0, 8.0])\n","alpha = 0.1\n","iterations = 200"]},
  {"cell_type":"markdown","metadata":{},"source":["## Practical Programming\n","Implement 1D linear regression with gradient descent using NumPy only.\n","Return (theta, y_pred) where theta is a scalar coefficient."]},
  {"cell_type":"code","metadata":{},"execution_count":null,"source":["def linear_regression_gd_1d(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int):\n","    # X shape (m, 1); y shape (m,)\n","    m = X.shape[0]\n","    theta = 0.0\n","    for _ in range(iterations):\n","        y_pred = theta * X[:,0]\n","        error = y_pred - y\n","        grad = (1.0/m) * np.sum(error * X[:,0])\n","        theta -= alpha * grad\n","    y_pred = theta * X[:,0]\n","    return round(theta, 4), np.round(y_pred, 4)"]},
  {"cell_type":"code","metadata":{},"execution_count":null,"source":["# Self-check tests (do not modify expected thresholds)\n","theta, preds = linear_regression_gd_1d(X, y, alpha, iterations)\n","print('theta:', theta)\n","print('preds:', preds)\n","assert abs(theta - 2.0) < 0.05, 'theta should be close to 2.0'\n","assert np.allclose(preds, y, atol=0.2), 'predictions should approximate y'\n","print('All tests passed.')"]},
  {"cell_type":"markdown","metadata":{},"source":["## Reflection\n","Briefly explain your approach and any choices you made (learning-rate, iterations)."]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}},
 "nbformat": 4,
 "nbformat_minor": 5
}

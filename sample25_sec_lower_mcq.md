# NOAI Singapore 2025 MCQ

## Lower Secondary (Grades 7 - 8)

## Question 1
**A fitness tracking app offers great features if you let it constantly track your location and health data. What trade-off does this illustrate?**

A) Gaining convenience and personalized insights at the cost of giving up some privacy about your personal data  
B) There is no trade-off; more data collection is purely good  
C) Losing all your fitness progress if you don’t share data  
D) There’s a trade-off between the app’s cost and its size, not data

**Answer: A**

**Explanation:** Many smart apps provide useful personalized services but require collecting personal information. This creates a convenience vs. privacy trade-off.

---

## Question 2
**If a self-driving car causes an accident, who is generally considered responsible for the decision the AI made?**

A) The humans behind the AI (manufacturers, programmers, or operators) are responsible for its behavior  
B) The AI itself, since it “decided,” should be punished  
C) No one is accountable because a computer made the choice  
D) The nearest human bystander is held responsible

**Answer: A**

**Explanation:** Responsibility falls on the people and organizations that design, program, and deploy AI.

---

## Question 3
**A social media AI shows you only posts you agree with. Why could this be a problem?**

A) It can create a “filter bubble,” limiting your exposure to different viewpoints and skewing your perspective  
B) It will always show wrong information from now on  
C) It might show you too many diverse opinions, causing confusion  
D) It will drain your phone battery much faster

**Answer: A**

**Explanation:** Echo chambers can polarize opinions and limit balanced understanding.

---

## Question 4
**A company’s hiring AI was trained on past data where most hires were men. Now it prefers male applicants. What does this illustrate?**

A) The AI has learned a gender bias from biased historical data, leading to unfair hiring recommendations  
B) The AI is malfunctioning technically and needs a reboot  
C) Women must have had weaker resumes on average  
D) AI systems cannot be biased

**Answer: A**

**Explanation:** The AI reflects bias present in training data; biased data leads to biased outcomes.

---

## Question 5
**AI can create deepfakes. What is a major concern about this technology?**

A) It can be used to spread misinformation or deceive people by making them believe fake events are real  
B) It dramatically improves video quality for old movies  
C) It requires special glasses to tell apart real from fake  
D) Only governments can make deepfakes

**Answer: A**

**Explanation:** Deepfakes can impersonate people and spread fraud or propaganda.

---

## Question 6
**Cities use AI-powered cameras to scan crowds. What is a potential downside of this surveillance technology?**

A) It could invade privacy and be misused to monitor people who have not done anything wrong  
B) It always misidentifies everyone  
C) It will automatically eliminate all crime  
D) Criminals can 100% evade it, so it’s pointless

**Answer: A**

**Explanation:** Surveillance benefits must be weighed against privacy and civil liberties.

---

## Question 7
**Which action can help ensure an AI system behaves ethically and safely?**

A) Having human experts oversee its critical decisions and regularly check for errors or biases  
B) Removing all human involvement and letting the AI run completely on its own  
C) Keeping the AI’s decision process secret so nobody interferes  
D) Training the AI once and never updating or evaluating it again

**Answer: A**

**Explanation:** Human oversight and regular evaluation are key for responsible AI.

---

## Question 8
**Why do AI developers split data into a training set and a testing set?**

A) To see if the AI can generalize — the test set checks performance on new, unseen data  
B) To give the AI some time off between data sets  
C) To confuse the AI so it learns faster  
D) To use up more computer memory without reason

**Answer: A**

**Explanation:** Separate test sets reveal overfitting and measure real generalization.

---

## Question 9
**Which scenario is an example of rule-based or “symbolic” AI?**

A) A chatbot that uses a fixed list of if-then rules written by programmers to respond to questions  
B) A photo app that improves face recognition by training on millions of images  
C) A spam filter that learns to detect spam by analyzing examples  
D) A voice assistant that gets better via repeated data training

**Answer: A**

**Explanation:** Symbolic AI uses human-written rules; ML improves from data.

---

## Question 10
**“Garbage in, garbage out” — what does this mean for training AI?**

A) Poor-quality or incorrect data leads to bad rules and poor results  
B) Any code bug turns outputs into garbage data  
C) AI should be trained using literal garbage examples  
D) Robots must empty trash cans to improve performance

**Answer: A**

**Explanation:** Bad data yields bad models; input quality determines output quality.

---

## Question 11
**What is an example of inclusive design in creating an AI voice assistant?**

A) Training on voices of different ages, accents, and genders so it understands everyone  
B) Recognizing only one accent to simplify the model  
C) Responding only to voices similar to the developer’s  
D) Limiting use to one region

**Answer: A**

**Explanation:** Diverse datasets help assistants work well for a broad population.

---

## Question 12
**A face recognition system struggles with masks or heavy sunglasses. What does this tell us?**

A) It wasn’t trained on images with masks or glasses, so it fails when conditions differ from training data  
B) The concept of a face is impossible for AI to recognize  
C) The AI has stopped working entirely  
D) Masks and sunglasses block AI sensors

**Answer: A**

**Explanation:** Models need exposure to real-world variations to generalize.

---

## Question 13
**You train an AI with 900 dog photos and 100 cat photos. It labels most new pictures as “dog.” Why?**

A) The training data was heavily imbalanced toward dogs, so the AI became biased  
B) The AI has something against cats personally  
C) 100 cat photos should have been enough  
D) The AI decided cats and dogs are the same

**Answer: A**

**Explanation:** Class imbalance biases predictions toward the majority class.

---

## Question 14
**How could you improve the model so it recognizes cats better?**

A) Provide more cat photos or otherwise balance the training data  
B) Remove dog photos and only train on cats  
C) Verbally tell the AI “Those are cats” and re-run it  
D) Stop training to avoid confusion

**Answer: A**

**Explanation:** Balance the dataset (more cat samples, augmentation, sampling) to reduce bias.

---

## Question 15
**As AI automates some jobs, what is a positive way society can respond?**

A) Retrain and reskill workers for new roles that AI can’t do well  
B) Do nothing and let people remain jobless  
C) Halt all AI development  
D) Ignore technological progress and hope it reverses

**Answer: A**

**Explanation:** Education and adaptation help workers transition to emerging roles.

---

## Question 16
**Why is it important to have diversity among people who design and train AI systems?**

A) A diverse team can identify biases or blind spots that a uniform team might miss  
B) It isn’t important; AI is always neutral  
C) Law requires every group even without contribution  
D) Only programming language diversity matters

**Answer: A**

**Explanation:** Diverse perspectives improve fairness and inclusivity.

---

## Question 17
**A medical test catches 99% of people with a disease but wrongly flags some healthy people. What can we say?**

A) High recall (sensitivity) but lower precision — finds almost all real cases at the cost of more false alarms  
B) High precision but low recall  
C) Perfect in both precision and recall  
D) Bad test since it’s not 100% correct

**Answer: A**

**Explanation:** Prioritizing recall can be acceptable when missing a true case is worse than false alarms.

---

## Question 18
**Which of these is a main concern of AI ethics?**

A) Ensuring AI decisions are fair, transparent, and do not harm individuals or groups  
B) Making AI run as fast as possible at any cost  
C) Keeping how AI works completely secret  
D) Designing AI solely to maximize profits

**Answer: A**

**Explanation:** Ethics emphasizes fairness, transparency, privacy, accountability, and safety.

---

## Question 19
**Which task is AI especially well-suited for compared to a person?**

A) Examining thousands of medical scans quickly to detect anomalies  
B) Understanding a patient’s feelings and providing emotional support  
C) Making a judgment call on a completely new situation with no prior data  
D) Deciding the fairest punishment in a complex legal case purely by calculation

**Answer: A**

**Explanation:** AI excels at large-scale pattern detection when well-trained.

---

## Question 20
**What is a benefit of explainable AI (XAI) in critical applications?**

A) It helps people understand why the AI made a decision, building trust and enabling error/bias checks  
B) It makes AI run much faster and use less memory  
C) It ensures the AI keeps its algorithms secret  
D) It allows AI to operate without human oversight

**Answer: A**

**Explanation:** XAI increases transparency and accountability in high-stakes domains.

---
